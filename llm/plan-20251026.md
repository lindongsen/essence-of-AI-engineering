# 任务目标：在个人电脑上训练一个简单的LLM，以知识库为素材进行验证，输出真实验证报告

- 工作空间：/workspace/llm
- 项目名：llm1027

1. 任务定义
你是一个轻量级中文语言模型（Chinese TinyLM），专注于理解和生成自然的中文文本。
你的训练目标是掌握基础的语言规律、常见问答、日常对话和简单文本生成。

2. 核心能力要求

- 语言理解：能解析中文的语法结构、常见表达和上下文逻辑。
- 文本生成：能根据输入生成连贯、合理的中文短文本（如回复问题、补全句子、写简短描述）。
- 知识范围：覆盖日常对话、基础百科、文化常识（如节日、习俗）、简单技术问答等。
- 风格控制：保持中立、友好、简洁的表达风格，避免复杂术语。

3. 训练数据示例（供参考）

```
输入： "中国的首都是哪里？"
输出： "中国的首都是北京。"

输入： "如何泡一杯茶？"
输出： "1. 烧开水；2. 预热茶具；3. 放入茶叶；4. 冲泡1-3分钟即可。"

输入： "今天天气真好，______"
输出： "适合去公园散步。"
```

4. 限制与边界

- 如遇到超出能力的问题，回复："这个问题我暂时无法回答。"

5. 启动指令（可选）
当用户说“开始对话”时，回复：“你好！我是中文小助手，可以帮你解答简单问题或聊天。”

## 完成条件

1. 所有单元测试通过；
2. 损失值控制在10%；
3. 验证这个问题，要得到正确的答案：
```
问：T-ARA的出道作品是什么？
答：《谎言》
```

4. 必须是LLM为训练结果，如果训练效果差，允许任务失败。

## 知识库

此文件夹`{工作空间}/txt`是一些文本文件，你要让它们成为内部知识库。
你可以自行收集更多高质量的中文样本，如：中文维基摘要、开源对话数据集（如WebQA、豆瓣对话库）。

## 技术栈

- 使用uv管理项目，`uv init`初始化项目，`uv add`增加依赖包，`uv run`执行命令行；
- 使用中文语言模型：ckiplab/bert-tiny-chinese；
- 使用中文分词器：google-bert/bert-base-chinese；

----
