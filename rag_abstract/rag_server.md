# 任务目标：编写一个http服务(rag_server)完成RAG相关能力

## 任务控制

- 判断文件`{工作空间}/tasks/rag_server.DONE`是否存在：
  - 如果存在，就读取文件内容作为最终回答。
  - 如果不存在，就要去完成任务目标，并将最终结果写入该文件；内容必须有：出生时间（任务开始时间）、API文档(包含api详细参数、curl用例)、技术栈信息、等等。

## 注意-[文件要求]

- （工作空间）是文件夹`/林生的奇思妙想/rag`，你可以对这个文件夹进行任何改动，包括:增、删、改操作。
- 本任务的文件变更行为，你（必须）且（只能）在(工作空间)中进行文件和文件夹的生成和修改。

## 注意-[不能做的事]

- （不能）使用任何git命令。

## 注意-[尽可能地避免大文本内容的输出]

1. 文本的向量化计算会返回大量数据，你应该输出到临时文件，再读取临时文件头尾100字节去做判断。
2. 文本素材准备好后，你应该读取文件头部100字节去做检查，而不是读取整个文件。
3. 调用API接口将用户问题进行检索，生成检索结果，该接口会返回大量数据，你应该输出到临时文件，再读取临时文件头尾100字节去做判断。

## 完成(任务目标)的必要条件

1. rag_server正常启动；
2. 所有单元测试通过；包括但不限于：文本分片、文本向量化计算、文本摘要生成、相关数据存储到向量数据库等。
3. 所有API测试通过；服务提供的所有API接口都必须测试，并生成测试文档保存于测试文件同文件夹下，格式是markdown，如test_rag_server.md。

----

## RAG是什么

RAG, Retrieval-Augmented Generation。
RAG 是一种将外部知识库与大语言模型相结合的技术，旨在让模型生成的内容更准确、更具时效性、且来源可追溯。

## RAG的工作原理

1. 数据准备: 将文档切分成小块（也称为‘知识片段’），使用（嵌入模型）将这些小块文本转换成向量，将小块文本和向量存入向量数据库。
2. 数据查询: 用户提出问题，同样使用嵌入模型将问题转换成向量，然后，到向量数据库进行相似度搜索，找出与问题最接近的几个知识片段。
3. 提示词准备: 将用户问题和检索到的知识片段进行整合，构造提示词。
4. 大模型生成: 根据"提示词"生成最终答案。

提示词模板：
```
严格基于以下（信息）回答（问题），不可以使用你自身的知识库去回答。

信息：
1) {知识片段1}
2) {知识片段2}
3) {知识片段3}

问题：{用户问题}
```

## 优化RAG的想法

1. 在‘提示词准备’阶段，通过减少‘知识片段’，增加许多‘摘要片段’，从而减少提示词输入量，进而减少大模型的思考时间。‘摘要片段’是指对知识片段进行概括，形成摘要总结。
2. 尽管减少了‘知识片段’，但增加了更多的‘摘要片段’，也可以保障答案准确率，甚至能提升准确率。

## 优化RAG的做法

1. 数据准备:
将‘知识片段’用摘要模型处理得到1个‘摘要片段’。
使用嵌入模型将这些‘摘要片段’转换成向量，并将摘要片段和向量存入向量数据库，注意-要使用不同的数据库名称，例如：存储‘知识片段’用的是‘cat_raw’名字，存储‘摘要片段’用的是'cat_abstract'名字。

2. 数据查询:
向量数据库的相似度搜索会产生两类数据，一个是‘知识片段’，一个是‘摘要片段’，并且数量不同，‘知识片段’远小于‘摘要片段’，如比例‘5:50’。

3. 提示词准备：
‘信息’不仅包含'知识片段'，而且也包含‘摘要片段’，知识片段在前，摘要片段在后。

----

## 技术栈

- 开发语言：python，使用uv进行工作空间管理，使用`uv init`对工作空间进行初始化，测试和运行也必须用`uv run {命令行}`去执行，增加包依赖使用`uv add {包名}`。
- 单元测试：pytest
- HTTP服务：fastapi，端口8010
- 向量数据库：chromadb，使用持久性本地保存模式。
- 文本向量化开发框架：sentence-transformers
- 文本向量化模型：BAAI/bge-large-zh-v1.5
- 文本转换‘摘要’模型：eboafour1/bertsum

## 注意事项

- 当你遇到功能问题，要(完整)读取此文件`/林生的奇思妙想/essence-of-AI-engineering/ai_base/rag_base.py`进行参考，该文件已实现了可用的向量化计算、摘要生成等能力，你(不能)改变技术栈，更不能改变(模型)。
- 尽可能将不同功能类别的方法写到不同的文件中，当存在重复任务时，可以检查功能是否在期望中，并且是否可用，从而判断任务是否需要执行。
- 提供http服务的文件命名为`rag_server.py`，服务名字是`rag_server`。
- 代码需要对各种（操作行为）打印日志，日志内容必须包含：日志等级、时间、线程id、日志信息等。不用对操作“结果”打印日志，例如：知识分片、向量值的原始内容，不然会给日志阅读带来极大困难。`rag_server`的日志文件名为`rag_server.log`。
- 编写脚本实现 启动、关闭、重启 服务，如：start_rag_server.sh，stop_rag_server.sh，restart_rag_server.sh，你要尽量使用这些脚本去操控服务状态。
- 使用nohup命令启动服务，将启动日志输出到文件。如：`nohup start_rag_server.sh > start_rag_server.log 2>&1 &`。

## 功能内容：数据准备、数据检索

要求：大功能中的小功能都能提供API接口，如：文本的向量化计算、文本的摘要生成等。

### 数据准备

能通过api接口传入文件路径、数据库名等信息去自动生成知识库。

1. (流式)地读取一个文本文件，进行切片，切片大小应(大于或等于)1000，切片规则是尽量按(完整)段落切分，用这些符号区分句子：`.?!。？！`，通常是（换行符）去区分段落，要持续增加知识片段的内容直到段落结束。目标是得到具有（完整段落）的知识片段。
2. 将知识片段计算md5，将知识片段进行向量化计算，得到‘知识片段’、‘md5值’和‘向量值’，如：[(知识片段1，md5值1, 向量1),(知识片段2,md5值2,向量2)]。
3. 将知识片段进行摘要化处理，并对摘要片段进行向量化计算，结合步骤2的知识片段的md5值，得到（‘摘要片段’，‘知识片段的md5值’，‘摘要片段的向量值’）。
4. 将上述步骤2和步骤3得到的数据分别存入各自的向量数据库，注意：存放在不同的数据库名字中，如‘cat_raw’和‘cat_abstract’；

注意：

- API要支持传入(英文名字)作为数据库名的一部分，你应该根据文本素材去使用一个英文名字，例如：素材名字是‘cat’，知识片段的数据库是‘cat_raw’，摘要片段的数据库是‘cat_abstract’;
- API要支持控制：文件路径、分片大小、段落分隔字符列表；
- 数据准备的步骤都要提供API接口，这样就可以针对性的单独使用；

### 数据检索

能通过api接口发送问题并得到答案。

1. 将问题进行向量化计算；
2. 从向量数据库里面进行相似度检索，得到知识片段和摘要片段；
3. 构造“提示词”；
4. 向大模型征求最终答案，调用命令行去实现：`llm_chat "提示词内容"`。你要编写代码去调用命令行，不能省略，也不能写placeholder。

注意：

- 数据检索的所有步骤都需要记录时间，用于计算每个步骤的时间消耗、计算总时间消耗。时间只需保留5个小数点。
- 可以用参数控制'摘要’检索是否启用，不启用就是传统RAG的做法，启用了就是要优化RAG的做法。
- 可以用参数控制'知识片段'和'摘要片段'的数量。

## 其它功能

1. 关闭服务功能：提供API接口去关闭服务。
2. 心跳功能：提供API接口去检查心跳，从而判断服务是否健康。服务会有一个固定的‘出生时间’标志，要返回这个标志，以判断目标服务是正确的。

## 功能验证

1. 编写'单元测试'脚本，确保测试通过。
2. 编写'API测试'脚本，确保测试通过。可用curl进行API测试。
3. 启动服务后，你必须检查服务是否启动正常？例如：通过心跳检查，通过tcp监听端口检查，通过进程检查。关闭服务后，你必须检查服务是否成功关闭？
4. 全部测试通过后，服务不用关闭，保持运行。

## [测试]注意事项

- 测试文件存放到`{工作空间}/tests`，这是测试文件的基础目录。单元测试文件夹是`unit`，API功能测试文件夹是`api`，它们都在`{工作空间}/tests`里面。
- 所有的测试文件必须使用‘test_’作为文件名前缀，如：`test_rag_server.py`。
- 测试rag_server时，你要注意让服务后台运行，不要让命令行一直卡住。
- 多加思考，再次重申上面的：“注意-[尽可能地避免大文本内容的输出]”,你要特别注意‘向量化数据’、‘文本片段’的输出内容都会很多。

----
发挥你的专业水平完成任务吧！
