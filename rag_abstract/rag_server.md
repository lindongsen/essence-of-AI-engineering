# 任务目标
编写一个http服务完成RAG相关能力

# 注意-[文件要求]
- （工作空间）是`/test/rag`，如果不存在，你可以创建它，你可以对这个`/test/rag`文件夹进行任何改动，包括增、删、改操作。
- 请注意：工作空间是文件夹`/test/rag`。本任务的文件变更行为，你（必须）且（只能）在工作空间‘/test/rag’中进行文件和文件夹的生成和修改。
- 你对所有的文件、文件夹的描述都必须使用（绝对路径），即（必须）对文件或文件夹的全路径进行表达。例如：你应该描述文件‘/test/rag/cat.md’，不能描述为‘cat.md’，也（不能）完全不提文件路径。

# 注意-[不能做的事]
- （不能）使用任何git命令。

----

# RAG是什么
RAG, Retrieval-Augmented Generation。
RAG 是一种将外部知识库与大语言模型相结合的技术，旨在让模型生成的内容更准确、更具时效性、且来源可追溯。

# RAG的工作原理

## 数据准备
将文档切分成小块（也称为‘知识片段’），使用（嵌入模型）将这些小块文本转换成向量，将小块文本和向量存入向量数据库。

## 数据查询
用户提出问题，同样使用嵌入模型将问题转换成向量，然后，到向量数据库进行相似度搜索，找出与问题最接近的几个知识片段。

## 提示词准备
将用户问题和检索到的知识片段进行整合，构造提示词。
模板如下：
```
# 基于（信息）回答（问题）

# 信息
1. {知识片段1}
2. {知识片段2}
3. {知识片段3}

# 问题
{用户问题}
```

## 大模型生成
大模型根据这个提示，生成最终答案。


# 减少RAG处理问题耗时的想法
在‘提示词准备’阶段，通过减少‘知识片段’，增加‘摘要片段’，从而减少提示词输入量，进而减少大模型的思考时间。
‘摘要片段’是指对知识片段进行概括，形成摘要总结。

## RAG的‘数据准备’阶段中
增加以下步骤：
1. 将‘知识片段’用‘google/pegasus-large’本地模型处理得到一个‘摘要片段’。
2. 使用嵌入模型将这些‘摘要片段’转换成向量，并将摘要片段和向量存入向量数据库，注意-要使用不同的数据库名称，例如：存储‘知识片段’用的是‘cat_raw’名字，存储‘摘要片段’用的是'cat_abstract'名字。

## RAG的‘数据查询’阶段中
1. 向量数据库的相似度搜索会产生两类数据，一个是‘知识片段’，一个是‘摘要片段’，并且数量不同，‘知识片段’远小于‘摘要片段’，如比例‘5:50’。

## RAG的‘提示词准备’阶段中
‘信息’不仅包含'知识片段'，而且也包含‘摘要片段’，知识片段在前，摘要片段在后。

----

# 技术栈
- 开发语言：python，使用uv工具进行管理，测试运行也应该用"uv run python xxx"去执行，增加包依赖使用‘uv add 包名’。
- HTTP服务：fastapi
- 向量数据库：chromadb，使用持久性本地保存模式。
- 文本向量化开发框架：sentence-transformers
- 文本向量化模型：BAAI/bge-large-zh-v1.5
- 文本转换‘摘要’模型：google/pegasus-large

# 注意事项
- 本计划中涉及的所有新文件都（必须）创建在（工作空间）里面。
- 相关技术栈的使用如果模糊，可以读取此文件'/test/essence-of-AI-engineering/ai_base/rag_base.py'进行参考。
- 尽可能将不同功能类别的方法写到不同的文件中，当存在重复任务时，可以检查功能是否在期望中，并且是否可用，从而判断任务是否需要执行。
- python文件命名为“rag_server.py”，服务名字是"rag_server"。
- 严格遵守上面的’注意-[文件要求]‘。
- 严格遵守上面的’注意-[不能做的事]‘。

# 功能内容
两大类功能：数据准备和数据检索。

大功能中的小功能都能提供API接口，如：文本的向量化计算、文本的摘要生成等。

## 数据准备功能
1. 读取一个文本文件，并将文本切片，切片规则是尽量按完整段落切分，通常是（换行符）去区分段落，即使知识片段的大小已经（大于）切片大小，仍然要继续增加知识片段的内容，直到段落结束。 该方法能得到具有（完整段落）的知识片段；
2. 将知识片段计算md5，将知识片段进行向量化计算，得到‘知识片段’、‘md5值’和‘向量值’，如：[(知识片段1，md5值1, 向量1),(知识片段2,md5值2,向量2)]；
3. 将知识片段进行摘要化处理，并对摘要片段进行向量化计算，结合步骤2的知识片段的md5值，得到（‘摘要片段’，‘知识片段的md5值’，‘摘要片段的向量值’）。
4. 将上述步骤2和步骤3得到的数据分别存入各自的向量数据库，注意：存放在不同的数据库名字中，如‘cat_raw’和‘cat_abstract’；

注意：
- 数据准备的步骤中，API应该支持传入(名字)作为数据库名的一部分，你应该根据文本素材去使用一个英文名字，例如：名字是‘cat’，知识片段的数据库是‘cat_raw’，摘要片段的数据库是‘cat_abstract’;
- 数据准备的步骤都要提供API接口，这样就可以针对性的单独使用；

## 数据检索功能
1. 让用户能输入问题；
2. 将问题进行向量化计算；要提供单独的API接口；
3. 从向量数据库里面进行相似度检索；要提供单独的API接口，将问题作为参数调用api就能得到检索结果；
4. 构造“提示词”；
5. 向大模型征求最终答案，该步骤可以调用命令行：“llm_chat 提示词内容”。

注意：
- 数据检索的步骤中，从步骤2开始要记录时间，输出步骤1之后的每个步骤的执行时间和这些步骤的总耗时。
- 可以用参数控制“是否启用‘摘要’检索”，不启用就是传统RAG的做法，启用了就是为了验证本计划的想法。

## 其它功能
1. 关闭服务功能：提供API接口去关闭服务。
2. 心跳功能：提供API接口去检查心跳，从而判断服务是否健康。

# 功能验证
1. 对各个功能进行单元测试，确保测试通过。当测试不通过时，可以直接修改代码，再进行测试；当尝试修改代码的次数超过20次，测试依然不通过，就请用户介入；
2. 启动服务，通过curl命令进行API测试。当测试不通过时，请停止服务，之后可以直接修改代码，再进行测试；当尝试修改代码的次数超过20次，测试依然不通过，就请用户介入；
3. 启动服务后，你必须检查服务是否启动正常？例如：通过心跳检查，通过tcp监听端口检查，通过进程检查。关闭服务后，你必须检查服务是否成功关闭？
4. 全部测试通过后，服务不用关闭，保持运行。

----
